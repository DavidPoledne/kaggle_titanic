{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b9ffb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Data matipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import MissingIndicator\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56a926b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# Imputation\n",
    "\n",
    "def knn_imputer(df):\n",
    "    #split predictor on numeric and categorical\n",
    "    numeric_predictors = df.select_dtypes(include=[\"int64\", \"float64\"])\n",
    "    categorical_predictors = df.select_dtypes(include=\"object\")\n",
    "\n",
    "    #get columns\n",
    "    numeric_columns = numeric_predictors.columns.values\n",
    "    categorical_columns = categorical_predictors.columns.values\n",
    "\n",
    "    #imputation by mean / most frequent\n",
    "    numeric_predictors = KNNImputer(n_neighbors=5).fit_transform(numeric_predictors)\n",
    "\n",
    "    # predictor numpy.array to pandas.dataframe\n",
    "    numeric_predictors = pd.DataFrame(numeric_predictors, columns=numeric_columns)\n",
    "    categorical_predictors = df[categorical_columns]\n",
    "    df_imputed = pd.concat([numeric_predictors, categorical_predictors], axis=1)\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def knn_imputer_ind(df):\n",
    "    #split predictor on numeric and categorical\n",
    "    numeric_predictors = df.select_dtypes(include=[\"int64\", \"float64\"])\n",
    "    categorical_predictors = df.select_dtypes(include=\"object\")\n",
    "\n",
    "\n",
    "    #get columns\n",
    "    numeric_columns = numeric_predictors.columns.values\n",
    "    categorical_columns = categorical_predictors.columns.values\n",
    "    \n",
    "    indicator = MissingIndicator(features=\"missing-only\")\n",
    "    missing_mask = indicator.fit_transform(numeric_predictors)\n",
    "\n",
    "    numeric_predictors_miss = numeric_predictors.isna().sum()\n",
    "    numeric_predictors_miss = numeric_predictors_miss[numeric_predictors_miss != 0].index.values\n",
    "\n",
    "    miss_list = []\n",
    "    for col in numeric_predictors_miss:\n",
    "        miss_list.append(f\"{col}_was_misssing\")\n",
    "\n",
    "\n",
    "    indicator_df = pd.DataFrame(missing_mask, columns=miss_list)\n",
    "\n",
    "    #imputation by mean\n",
    "    numeric_predictors = KNNImputer(n_neighbors=5).fit_transform(numeric_predictors)\n",
    "\n",
    "    # predictor numpy.array to pandas.dataframe\n",
    "    numeric_predictors = pd.DataFrame(numeric_predictors, columns=numeric_columns)\n",
    "    numeric_predictors = pd.concat([numeric_predictors, indicator_df], axis=1)\n",
    "    categorical_predictors = df[categorical_columns]\n",
    "    df_imputed = pd.concat([numeric_predictors, categorical_predictors], axis=1)\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# Convert categorical features into boolean\n",
    "\n",
    "def get_dummies_fun(df):\n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "    return df\n",
    "\n",
    "def label_encoder_fun(df):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for predictor in df.columns:\n",
    "        if df[predictor].dtype == object:\n",
    "            df[predictor] = le.fit_transform(df[predictor])\n",
    "    return df\n",
    "\n",
    "\n",
    "# Scaling\n",
    "\n",
    "def standardization(x_train, x_test):\n",
    "    columns = x_train.columns.values\n",
    "    index = x_train.index\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_train = pd.DataFrame(x_train, columns=columns, index=index)\n",
    "\n",
    "    columns = x_test.columns.values\n",
    "    index = x_test.index\n",
    "    scaler = StandardScaler()\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    x_test = pd.DataFrame(x_test, columns=columns, index=index)\n",
    "    return x_train, x_test\n",
    "\n",
    "def normalization(x_train, x_test):\n",
    "    columns = x_train.columns.values\n",
    "    index = x_train.index\n",
    "    scaler = MinMaxScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_train = pd.DataFrame(x_train, columns=columns, index=index)\n",
    "\n",
    "    columns = x_test.columns.values\n",
    "    index = x_test.index\n",
    "    scaler = MinMaxScaler()\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "    x_test = pd.DataFrame(x_test, columns=columns, index=index)\n",
    "    return x_train, x_test\n",
    "\n",
    "def no_scaling_fun(x_train, x_test):\n",
    "    return x_train, x_test\n",
    "\n",
    "\n",
    "# Features selection\n",
    "\n",
    "random_search__n_iter = 10\n",
    "def predictors_selector(x_train, y_train):\n",
    "    model = LogisticRegression(penalty=\"l1\", max_iter=500, solver=\"liblinear\",)\n",
    "    pipe = Pipeline([\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    model_params = {\n",
    "        \"C\": np.linspace(0.00001, 0.1)\n",
    "    }\n",
    "    rand_search = RandomizedSearchCV(model, model_params, n_iter=random_search__n_iter)\n",
    "    rand_search.fit(x_train, y_train)\n",
    "    best_params = rand_search.best_params_\n",
    "    best_c = best_params[\"C\"]\n",
    "    log_reg_model = LogisticRegression(penalty=\"l1\", C=best_c, max_iter=10000, solver=\"liblinear\")\n",
    "    log_reg_model.fit(x_train, y_train)\n",
    "    coefs = log_reg_model.coef_\n",
    "    columns = x_train.columns.values\n",
    "    non_zero_mask = coefs != 0\n",
    "    selected_predictors = columns[non_zero_mask[0]]\n",
    "    x_train = x_train[selected_predictors]\n",
    "    return x_train\n",
    "\n",
    "def no_feature_selector(x_train, y_train):\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "120ea78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_test = pd.read_csv(\"../data/test.csv\")\n",
    "df_combine = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "837fa3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First look at data\n",
    "df_combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "939a9b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 12)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of data\n",
    "df_combine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e5c7b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.294882</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.295479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>378.020061</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>14.413493</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.758668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>328.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>982.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived       Pclass          Age        SibSp  \\\n",
       "count  1309.000000  891.000000  1309.000000  1046.000000  1309.000000   \n",
       "mean    655.000000    0.383838     2.294882    29.881138     0.498854   \n",
       "std     378.020061    0.486592     0.837836    14.413493     1.041658   \n",
       "min       1.000000    0.000000     1.000000     0.170000     0.000000   \n",
       "25%     328.000000    0.000000     2.000000    21.000000     0.000000   \n",
       "50%     655.000000    0.000000     3.000000    28.000000     0.000000   \n",
       "75%     982.000000    1.000000     3.000000    39.000000     1.000000   \n",
       "max    1309.000000    1.000000     3.000000    80.000000     8.000000   \n",
       "\n",
       "             Parch         Fare  \n",
       "count  1309.000000  1308.000000  \n",
       "mean      0.385027    33.295479  \n",
       "std       0.865560    51.758668  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     7.895800  \n",
       "50%       0.000000    14.454200  \n",
       "75%       0.000000    31.275000  \n",
       "max       9.000000   512.329200  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of numerical data\n",
    "df_combine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e7e0e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309</td>\n",
       "      <td>1309</td>\n",
       "      <td>1309</td>\n",
       "      <td>295</td>\n",
       "      <td>1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1307</td>\n",
       "      <td>2</td>\n",
       "      <td>929</td>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>843</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name   Sex    Ticket        Cabin Embarked\n",
       "count               1309  1309      1309          295     1307\n",
       "unique              1307     2       929          186        3\n",
       "top     Kelly, Mr. James  male  CA. 2343  C23 C25 C27        S\n",
       "freq                   2   843        11            6      914"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of object data\n",
    "df_combine.describe(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c46c94fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived       float64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Types of data\n",
    "df_combine.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9eb889c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "Survived        418\n",
       "Pclass            0\n",
       "Name              0\n",
       "Sex               0\n",
       "Age             263\n",
       "SibSp             0\n",
       "Parch             0\n",
       "Ticket            0\n",
       "Fare              1\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing data\n",
    "df_combine.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4108123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "df_train = df_train.drop(\"Name\", axis=1) # has no meaning \n",
    "df_train = df_train.drop(\"Cabin\", axis=1) # high percentage of missing data\n",
    "df_train = df_train.drop(\"Ticket\", axis=1) # lot of unique string data type\n",
    "df_train = df_train.drop(\"PassengerId\", axis=1) # has no meaning\n",
    "\n",
    "# same for test data\n",
    "df_test = df_test.drop(\"Name\", axis=1) # has no meaning \n",
    "df_test = df_test.drop(\"Cabin\", axis=1) # high percentage of missing data\n",
    "df_test = df_test.drop(\"Ticket\", axis=1) # lot of unique string data type\n",
    "df_test = df_test.drop(\"PassengerId\", axis=1) # has no meaning\n",
    "\n",
    "# same for df_combine\n",
    "df_combine = df_combine.drop(\"Name\", axis=1) # has no meaning \n",
    "df_combine = df_combine.drop(\"Cabin\", axis=1) # high percentage of missing data\n",
    "df_combine = df_combine.drop(\"Ticket\", axis=1) # lot of unique string data type\n",
    "df_combine = df_combine.drop(\"PassengerId\", axis=1) # has no meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e682483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    418\n",
       "Pclass        0\n",
       "Sex           0\n",
       "Age         263\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          1\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing data\n",
    "df_combine.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05b8a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation of Age\n",
    "df_train = knn_imputer(df_train)\n",
    "df_test = knn_imputer(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd6f2ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Sex         0\n",
       "Embarked    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing train data\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41fb524c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Sex         0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing test data\n",
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2655accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop remaining rows with missing data\n",
    "# there is only few missing rows\n",
    "df_train = df_train.dropna()\n",
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0af43843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Sex         0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing data\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c18df23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical features into numerical\n",
    "df_train = label_encoder_fun(df_train)\n",
    "df_test = label_encoder_fun(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f72d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data on predictor and responsible feature\n",
    "x_train = df_train.drop(\"Survived\", axis=1)\n",
    "y_train = df_train.Survived\n",
    "\n",
    "# Change df_test on x_test\n",
    "x_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7af5b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "x_train, x_test = standardization(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1cfcbb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set scorring\n",
    "scorring = \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e650fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features selection:\n",
    "x_train = predictors_selector(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4586fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_house_prices)",
   "language": "python",
   "name": "venv_house_prices"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
